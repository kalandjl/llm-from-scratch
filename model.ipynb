{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69190936-2cb0-43d8-ade5-62beaaa0eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: source code for 'requests' python libraray\n",
    "text = open(\"data/requests.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c746ba6-353b-47cd-b79f-fa3edf0d3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sorted list of all unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# string-to-integer mapping\n",
    "stoi = { char:i for i,char in enumerate(chars) }\n",
    "\n",
    "# integer-to-string mapping\n",
    "itos = { i:char for i,char in enumerate(chars) }\n",
    "\n",
    "# lookup functions for the mappings\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "# encode the entire text file and convert to a numpy array\n",
    "data = np.array(encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f140ef1f-7dec-441a-b7fe-eb4448291514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Max input sequence length\n",
    "max_seq_len = 1000\n",
    "\n",
    "n_embd = 128\n",
    "\n",
    "# Initialize embedding matrix\n",
    "embedding_matrix = np.random.randn(vocab_size, n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45bb0e9-1941-434c-8e8f-4681cd4ad403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_pred, y_true):\n",
    "\n",
    "    # Add a small epsilon to the prediction to avoid log(0), which is undefined.\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    # cross-entropy formula\n",
    "    loss = -np.sum(y_true * np.log(y_pred + epsilon))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feabbdb1-b5f2-4579-97f4-e80bc4f055cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_attention_block:\n",
    "    def __init__(self, W_query, W_key, W_value):\n",
    "        \n",
    "        self.W_query   = W_query \n",
    "        self.W_key = W_key \n",
    "        self.W_value = W_value\n",
    "\n",
    "        self.W_query_grad = np.zeros_like(self.W_query)\n",
    "        self.W_key_grad = np.zeros_like(self.W_key)\n",
    "        self.W_value_grad = np.zeros_like(self.W_value)\n",
    "\n",
    "        self.cache = {}\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        self.cache['x'] = x\n",
    "\n",
    "        B, T, n_embd = x.shape\n",
    "        \n",
    "        queries = x @ self.W_query    # (B, T, n_embd)\n",
    "        keys = x @ self.W_key         # (B, T, n_embd) \n",
    "        values = x @ self.W_value     # (B, T, n_embd)\n",
    "\n",
    "        self.cache['queries'] = queries  \n",
    "        self.cache['keys'] = keys\n",
    "        self.cache['values'] = values\n",
    "\n",
    "        # Make key query attention pattern\n",
    "        attention_scores = (queries @ keys.transpose(0, 2, 1)) / np.sqrt(keys.shape[-1])\n",
    "        self.cache['attention_scores'] = attention_scores\n",
    "        \n",
    "        # Create mask once\n",
    "        if not hasattr(self, '_mask') or self._mask.shape != (T, T):\n",
    "            self._mask = np.triu(np.ones((T, T)), k=1).astype(bool)\n",
    "        \n",
    "        # Apply mask more efficiently\n",
    "        attention_scores_masked = attention_scores.copy()\n",
    "        for b in range(B):  # Apply mask to each batch\n",
    "            attention_scores_masked[b, self._mask] = -np.inf\n",
    "        \n",
    "        # softmax\n",
    "        stable_scores = attention_scores_masked - np.max(attention_scores_masked, axis=-1, keepdims=True)\n",
    "        attention_weights = np.exp(stable_scores) / np.sum(np.exp(stable_scores), axis=-1, keepdims=True)\n",
    "        self.cache['attn_weights'] = attention_weights\n",
    "        \n",
    "        # final output: attended inputs\n",
    "        output = attention_weights @ values  # (B, T, n_embd)\n",
    "\n",
    "        return output\n",
    "        \n",
    "    def backward(self, d_output):\n",
    "        \n",
    "        # Gradient through: output = attention_weights @ values\n",
    "        d_attention_weights = d_output @ self.cache['values'].transpose(0, 2, 1)\n",
    "        d_values = self.cache['attn_weights'].transpose(0, 2, 1) @ d_output  \n",
    "\n",
    "        # Apply jacobian to backprop through the softmax function\n",
    "        d_attention_scores = self.cache['attn_weights'] * (d_attention_weights - np.sum(d_attention_weights * self.cache['attn_weights'], axis=-1, keepdims=True))\n",
    "\n",
    "        # Scale factor\n",
    "        scale = 1.0 / np.sqrt(self.cache['keys'].shape[-1])\n",
    "        \n",
    "        # Gradient through scaling\n",
    "        d_attention_scores_scaled = d_attention_scores * scale\n",
    "        \n",
    "        # Gradient through: queries @ keys.transpose(0, 2, 1)\n",
    "        d_queries = d_attention_scores_scaled @ self.cache['keys']\n",
    "        d_keys = d_attention_scores_scaled.transpose(0, 2, 1) @ self.cache['queries']\n",
    "\n",
    "        # Gradient through: queries = x @ W_query (and same for keys, values)\n",
    "        self.W_query_grad, d_x_from_queries = self.linear_backward(d_queries, self.W_query, self.cache['x'])\n",
    "        self.W_key_grad, d_x_from_keys = self.linear_backward(d_keys, self.W_key, self.cache['x'])  \n",
    "        self.W_value_grad, d_x_from_values = self.linear_backward(d_values, self.W_value, self.cache['x'])\n",
    "        \n",
    "        # Sum gradients from all three paths\n",
    "        d_x = d_x_from_queries + d_x_from_keys + d_x_from_values\n",
    "        return d_x\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_backward(d_output, W, x_from_cache):\n",
    "        d_x = d_output @ W.T\n",
    "        x_reshaped, dy_reshaped = x_from_cache.reshape(-1, x_from_cache.shape[-1]), d_output.reshape(-1, d_output.shape[-1])\n",
    "        d_W = x_reshaped.T @ dy_reshaped\n",
    "        return d_W, d_x\n",
    "\n",
    "    def optimizer (self, learning_rate):\n",
    "        self.W_query -= (self.W_query_grad * learning_rate)\n",
    "        self.W_key -= (self.W_key_grad * learning_rate)\n",
    "        self.W_value-= (self.W_value_grad * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b1ccc6-499a-4761-ab57-e92fb293db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_head_attention:\n",
    "    def __init__ (self, n_heads, n_embd):\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = n_embd // n_heads\n",
    "\n",
    "        # Create multiple attention heads\n",
    "        self.heads = []\n",
    "        for i in range(n_heads):\n",
    "            # Each head gets its own Q, K, V projections\n",
    "            W_q = np.random.randn(n_embd, self.head_dim) * 0.02\n",
    "            W_k = np.random.randn(n_embd, self.head_dim) * 0.02\n",
    "            W_v = np.random.randn(n_embd, self.head_dim) * 0.02\n",
    "            self.heads.append(self_attention_block(W_q, W_k, W_v))\n",
    "        \n",
    "        # Output projection to combine all heads\n",
    "        self.W_output = np.random.randn(n_embd, n_embd) * 0.02\n",
    "\n",
    "        self.W_output_grad = np.zeros_like(self.W_output)\n",
    "\n",
    "        self.cache = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_backward(d_output, W, x_from_cache):\n",
    "\n",
    "        # d_W = x.T @ dy\n",
    "        # d_x = dy @ W.T\n",
    "\n",
    "        d_x = d_output @ W.T\n",
    "\n",
    "        # Flaten weight and input arrays to calculate weight gradients\n",
    "        x_reshaped, dy_reshaped = x_from_cache.reshape(-1, x_from_cache.shape[-1]), d_output.reshape(-1, d_output.shape[-1])\n",
    "        d_W = x_reshaped.T @ dy_reshaped\n",
    "\n",
    "        return d_W, d_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run each head\n",
    "        head_outputs = []\n",
    "        for head in self.heads:\n",
    "            head_outputs.append(head.forward(x))\n",
    "        \n",
    "        # Concatenate along embedding dimension\n",
    "        concat_output = np.concatenate(head_outputs, axis=-1)  # (B, T, n_embd)\n",
    "        self.cache['concat_output'] = concat_output\n",
    "        \n",
    "        # Final projection\n",
    "        output = concat_output @ self.W_output\n",
    "        return output\n",
    "\n",
    "    def backward(self, d_output):\n",
    "\n",
    "        self.W_output_grad, d_concat = self.linear_backward(d_output, self.W_output, self.cache['concat_output'])\n",
    "\n",
    "        head_gradients = np.split(d_concat, self.n_heads, axis=-1)\n",
    "\n",
    "        # Return sum of head's gradients\n",
    "        d_x_sum = None\n",
    "        for i, head_grad in enumerate(head_gradients):\n",
    "            d_x = self.heads[i].backward(head_grad)\n",
    "            if d_x_sum is None:\n",
    "                d_x_sum = d_x\n",
    "            else:\n",
    "                d_x_sum += d_x \n",
    "        \n",
    "        return d_x_sum\n",
    "\n",
    "    def optimizer(self, learning_rate):\n",
    "        self.W_output -= (self.W_output_grad * learning_rate)\n",
    "        for head in self.heads:\n",
    "            head.optimizer(learning_rate)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e42dcd-5ea2-4a38-900f-6dbd42064fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm:\n",
    "    def __init__ (self, n_embd):\n",
    "\n",
    "        self.n_embd = n_embd\n",
    "        self.gamma = np.ones((n_embd,))\n",
    "        self.beta = np.zeros((n_embd,))\n",
    "\n",
    "        self.gamma_grad = np.zeros_like(self.gamma)\n",
    "        self.beta_grad = np.zeros_like(self.beta)\n",
    "\n",
    "        self.cache = {}\n",
    "        \n",
    "    def forward (self, x):\n",
    "\n",
    "        # x: (B, T, n_embd)\n",
    "        mean = x.mean(axis=-1, keepdims=True)\n",
    "        variance = x.var(axis=-1, keepdims=True)\n",
    "        epsilon = 1e-5 # A standard small value for epsilon\n",
    "\n",
    "        # Input vector scaled to have a mean of 0 and variance of 1\n",
    "        x_normalized = (x - mean) / np.sqrt(variance + epsilon)\n",
    "        \n",
    "        # Cache values needed for the backward pass\n",
    "        self.cache['x_normalized'] = x_normalized\n",
    "        self.cache['gamma'] = self.gamma\n",
    "        self.cache['std_dev'] = np.sqrt(variance + epsilon)\n",
    "\n",
    "        return x_normalized * self.gamma + self.beta\n",
    "\n",
    "    \n",
    "    def backward (self, d_output):\n",
    "\n",
    "        # Calculate gradients for gamma and beta\n",
    "        # These are summed over the batch and time dimensions to match the parameter shapes\n",
    "        self.beta_grad = np.sum(d_output, axis=(0,1))\n",
    "        self.gamma_grad = np.sum(d_output * self.cache['x_normalized'], axis=(0,1))\n",
    "\n",
    "        # Calculate the gradient for the input x (the error signal to pass back)\n",
    "        N = self.n_embd\n",
    "        std_dev = self.cache['std_dev']\n",
    "        x_norm = self.cache['x_normalized']\n",
    "        gamma = self.cache['gamma']\n",
    "\n",
    "        # Backprop through the scale and shift (y = gamma * x_norm + beta)\n",
    "        d_x_norm = d_output * gamma\n",
    "        \n",
    "        # Backprop through the normalization\n",
    "        sum1 = np.sum(d_x_norm, axis=-1, keepdims=True)\n",
    "        sum2 = np.sum(d_x_norm * x_norm, axis=-1, keepdims=True)\n",
    "        \n",
    "        d_x = (1 / (N * std_dev)) * (N * d_x_norm - sum1 - x_norm * sum2)\n",
    "        \n",
    "        return d_x\n",
    "        \n",
    "    def optimizer (self, learning_rate):\n",
    "        \n",
    "        self.gamma -= (self.gamma_grad * learning_rate)\n",
    "        self.beta -= (self.beta_grad * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc41611e-38e2-458b-b669-eb39c0955c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__ (self, W1, W2, n_attn_heads, n_embd):\n",
    "        self.W1 = W1\n",
    "        self.W2 = W2\n",
    "        self.multi_head_attention_block = multi_head_attention(n_attn_heads, n_embd)\n",
    "\n",
    "        self.W1_grad = np.zeros_like(self.W1)\n",
    "        self.W2_grad = np.zeros_like(self.W2)\n",
    "\n",
    "        self.layer_norm1 = LayerNorm(n_embd)\n",
    "        self.layer_norm2 = LayerNorm(n_embd)\n",
    "\n",
    "        self.cache = {}\n",
    "\n",
    "    def forward (self, x): \n",
    "\n",
    "        attn_output = self.multi_head_attention_block.forward(x)\n",
    "        self.cache['attn_output'] = attn_output\n",
    "\n",
    "        add_output_1 = x + attn_output  # Residual connection step\n",
    "        norm_output_1 = self.layer_norm1.forward(add_output_1)  # Layer norm step\n",
    "        self.cache['norm_output_1'] = norm_output_1\n",
    "                \n",
    "        hidden = norm_output_1 @ self.W1\n",
    "        self.cache['hidden'] = hidden\n",
    "        \n",
    "        hidden_activated = np.maximum(0, hidden)\n",
    "        self.cache['hidden_activated'] = hidden_activated \n",
    "        \n",
    "        processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
    "        self.cache['processed_vectors'] = processed_vectors\n",
    "\n",
    "        add_output_2 = norm_output_1 + processed_vectors   # Residual connection step\n",
    "        norm_output_2 = self.layer_norm2.forward(add_output_2) # Layer norm step\n",
    "        self.cache['norm_output_2'] = norm_output_2\n",
    "\n",
    "        return norm_output_2\n",
    "\n",
    "    def backward (self, d_output):\n",
    "\n",
    "        # Error gradient from last residiual connection step, calculated on LayerNorm.backwards()\n",
    "        d_add2 = self.layer_norm2.backward(d_output)\n",
    "\n",
    "        # Fork error signal\n",
    "        d_processed_vectors = d_add2\n",
    "        d_norm_output_1_from_residual = d_add2\n",
    "\n",
    "        # Put d_processed_vectors through FFN backprop\n",
    "        # Activated hidden layer\n",
    "        grad_W2, d_hidden_activated = self.linear_backward(d_processed_vectors, self.W2, self.cache['hidden_activated'])\n",
    "        self.W2_grad = grad_W2\n",
    "\n",
    "        # Relu backprop\n",
    "        d_hidden = d_hidden_activated * (self.cache['hidden'] > 0)\n",
    "\n",
    "        # Hidden layer\n",
    "        grad_W1, d_norm_output_1_from_ffn = self.linear_backward(d_hidden, self.W1, self.cache['norm_output_1'])\n",
    "        self.W1_grad = grad_W1\n",
    "\n",
    "        # Recombine error gradients \n",
    "        d_norm_output_1_total = d_norm_output_1_from_ffn + d_norm_output_1_from_residual\n",
    "\n",
    "        # Error gradient from first residiual connection step, calculated on LayerNorm.backwards()\n",
    "        d_add1 = self.layer_norm1.backward(d_norm_output_1_total)\n",
    "\n",
    "        d_attn_output = d_add1\n",
    "        d_x_from_residual = d_add1\n",
    "\n",
    "        # Attention block    \n",
    "        d_x_from_attention = self.multi_head_attention_block.backward(d_attn_output)\n",
    "\n",
    "        d_attn_input = d_x_from_residual + d_x_from_attention\n",
    "\n",
    "        return d_attn_input\n",
    "\n",
    "    def optimizer(self, learning_rate): \n",
    "\n",
    "        self.multi_head_attention_block.optimizer(learning_rate)\n",
    "\n",
    "        self.layer_norm1.optimizer(learning_rate)\n",
    "        self.layer_norm2.optimizer(learning_rate)\n",
    "        \n",
    "        self.W1 -= (self.W1_grad * learning_rate)\n",
    "        self.W2 -= (self.W2_grad * learning_rate)\n",
    "        \n",
    "    @staticmethod\n",
    "    def linear_backward(d_output, W, x_from_cache):\n",
    "\n",
    "        # d_W = x.T @ dy\n",
    "        # d_x = dy @ W.T\n",
    "\n",
    "        d_x = d_output @ W.T\n",
    "\n",
    "        # Flaten weight and input arrays to calculate weight gradients\n",
    "        x_reshaped, dy_reshaped = x_from_cache.reshape(-1, x_from_cache.shape[-1]), d_output.reshape(-1, d_output.shape[-1])\n",
    "        d_W = x_reshaped.T @ dy_reshaped\n",
    "\n",
    "        return d_W, d_x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce4f567-ea96-4ec9-9349-6fdcac190fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,embedding_matrix, temperature=1.0, max_sequence_length=1000, n_embd=128, n_transformers=12, ffwd_expansion_factor=4):\n",
    "\n",
    "        # Initialize weight matrices\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.position_matrix = np.random.randn(max_sequence_length, n_embd)\n",
    "\n",
    "        # Hidden layer initialization functions\n",
    "        \n",
    "        # Transformers \n",
    "        self.transformers = []\n",
    "        \n",
    "        for i in range(n_transformers):\n",
    "            \n",
    "            # Hidden layer initialization \n",
    "            W1 = np.random.randn(n_embd, n_embd * ffwd_expansion_factor) * np.sqrt(2.0 / n_embd)\n",
    "            W2 = np.random.randn(n_embd * ffwd_expansion_factor, n_embd) * np.sqrt(2.0 / (n_embd * ffwd_expansion_factor))\n",
    "\n",
    "            # Append transformer\n",
    "            self.transformers.append(Transformer(W1, W2, n_attn_heads=16, n_embd=n_embd))\n",
    "\n",
    "        self.cache = {} # A dictionary to store forward pass values\n",
    "\n",
    "        self.n_transformers = n_transformers\n",
    "\n",
    "        # Temperature hyperparameter\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Gradient buckets\n",
    "        self.embedding_matrix_grad = np.zeros_like(self.embedding_matrix)\n",
    "        self.position_matrix_grad = np.zeros_like(self.position_matrix)\n",
    "\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        \n",
    "        x_batch = np.array(x_batch)\n",
    "        if x_batch.ndim == 1:\n",
    "            x_batch = x_batch[None, :]  # Add batch dimension: (T,) -> (1, T)\n",
    "        \n",
    "        self.cache['x_batch'] = x_batch\n",
    "\n",
    "        # Output shape: (B, T, n_embd)\n",
    "        embd = self.embedding_matrix[x_batch]\n",
    "        self.cache['embd'] = embd\n",
    "\n",
    "        # Positional embeddings\n",
    "        B, T = x_batch.shape\n",
    "        pos = self.position_matrix[:T]  # Slice for sequence length\n",
    "        self.cache['pos'] = pos\n",
    "        \n",
    "        # Add position to token embeddings\n",
    "        attn_input = embd + pos\n",
    "        self.cache['attn_input'] = attn_input\n",
    "        \n",
    "        # Put data through transformers\n",
    "        transformer_output = attn_input\n",
    "        \n",
    "        for transformer in self.transformers:\n",
    "            transformer_output = transformer.forward(transformer_output)\n",
    "            \n",
    "        self.cache['transformer_output'] = transformer_output\n",
    "        \n",
    "        logits = transformer_output @ self.embedding_matrix.T\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def pred (self, x):\n",
    "\n",
    "        logits = self.forward(x)[0, -1]  # Get batch 0, last position\n",
    "        \n",
    "        scaled_logits = logits / self.temperature\n",
    "        \n",
    "        ## Apply softmax function to logits\n",
    "        stable_logits = scaled_logits - np.max(scaled_logits) # This ensures the largest logit is 0\n",
    "        preds = np.exp(stable_logits) / np.sum(np.exp(stable_logits))       \n",
    "        \n",
    "        char_pred = np.random.choice(range(0, len(chars)), p=preds)\n",
    "        \n",
    "        return char_pred\n",
    "\n",
    "    def calc_loss (self, logits, y_batch):\n",
    "\n",
    "        # Get the dimensions for indexing\n",
    "        B, T, C = logits.shape\n",
    "\n",
    "        # Stable softmax\n",
    "        max_logits = np.max(logits, axis=-1, keepdims=True)\n",
    "        stable_logits = logits - max_logits\n",
    "        exp_logits = np.exp(stable_logits)\n",
    "        probabilities = exp_logits / np.sum(exp_logits, axis=-1, keepdims=True)\n",
    "    \n",
    "        # Get the probabilities for the correct target characters using efficient indexing\n",
    "        correct_char_probs = probabilities[np.arange(B)[:, None], np.arange(T), y_batch]\n",
    "\n",
    "        # Calculate negative log likelihood\n",
    "        loss_array = -np.log(correct_char_probs + 1e-9)\n",
    "    \n",
    "        # Average the loss over the whole batch to get a single number\n",
    "        mean_loss = np.mean(loss_array)\n",
    "\n",
    "        self.loss = mean_loss\n",
    "        \n",
    "        # Return probabilities because they are the starting point for backpropagation\n",
    "        return mean_loss, probabilities\n",
    "\n",
    "    \n",
    "    # Calculates the gradients for a specific layer and it's resulting vector\n",
    "    @staticmethod\n",
    "    def linear_backward(d_output, W, x_from_cache):\n",
    "\n",
    "        # d_W = x.T @ dy\n",
    "        # d_x = dy @ W.T\n",
    "\n",
    "        d_x = d_output @ W.T\n",
    "\n",
    "        # Flaten weight and input arrays to calculate weight gradients\n",
    "        x_reshaped, dy_reshaped = x_from_cache.reshape(-1, x_from_cache.shape[-1]), d_output.reshape(-1, d_output.shape[-1])\n",
    "        d_W = x_reshaped.T @ dy_reshaped\n",
    "\n",
    "        return d_W, d_x\n",
    "\n",
    "\n",
    "    def backward (self, d_logits):\n",
    "\n",
    "        # Reset gradients at start of backward pass\n",
    "        self.embedding_matrix_grad.fill(0)\n",
    "        self.position_matrix_grad.fill(0)\n",
    "        \n",
    "        # Unembedding layer - handle tied weights correctly\n",
    "        d_transformer_output = d_logits @ self.embedding_matrix  # gradient w.r.t transformer output\n",
    "\n",
    "        transformer_output = self.cache['transformer_output']\n",
    "        \n",
    "        # Gradient w.r.t embedding matrix from unembedding (transposed)\n",
    "        B, T, n_embd = transformer_output.shape\n",
    "        transformer_output_flat = transformer_output.reshape(-1, n_embd)  # Shape: (B*T, n_embd)\n",
    "        d_logits_flat = d_logits.reshape(-1, d_logits.shape[-1])  # Shape: (B*T, vocab_size)\n",
    "        \n",
    "        unembedding_grad = transformer_output_flat.T @ d_logits_flat\n",
    "        \n",
    "        # Add unembedding gradient to embedding matrix gradients\n",
    "        self.embedding_matrix_grad += unembedding_grad.T\n",
    "        \n",
    "        # Loop in reverse order through transformers\n",
    "        current_grad = d_transformer_output\n",
    "        \n",
    "        for transformer in reversed(self.transformers):\n",
    "            current_grad = transformer.backward(current_grad)\n",
    "\n",
    "        d_attn_input = current_grad\n",
    "\n",
    "\n",
    "         # Split gradient between embeddings and positions (attn_input = embd + pos)\n",
    "        d_embed = d_attn_input  \n",
    "        d_pos = d_attn_input  \n",
    "        \n",
    "        # Update position matrix gradients\n",
    "        B, T = self.cache['x_batch'].shape\n",
    "        self.position_matrix_grad[:T] += np.sum(d_pos, axis=0)  # Sum over batch dimension\n",
    "    \n",
    "        # Perform reverse lookup on embedding array\n",
    "        np.add.at(self.embedding_matrix_grad, self.cache['x_batch'], d_embed)\n",
    "\n",
    "    def optimizer (self, learning_rate): \n",
    "\n",
    "        self.embedding_matrix -= (self.embedding_matrix_grad * learning_rate)\n",
    "        self.position_matrix -= (self.position_matrix_grad * learning_rate)\n",
    "        \n",
    "        for transformer in self.transformers:\n",
    "            transformer.optimizer(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6aef4e4-a5fd-4b7f-992a-eabd50c53183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1034086775.py:47: RuntimeWarning: divide by zero encountered in matmul\n",
      "  output = concat_output @ self.W_output\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1034086775.py:47: RuntimeWarning: overflow encountered in matmul\n",
      "  output = concat_output @ self.W_output\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1034086775.py:47: RuntimeWarning: invalid value encountered in matmul\n",
      "  output = concat_output @ self.W_output\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/3072446633.py:24: RuntimeWarning: divide by zero encountered in matmul\n",
      "  hidden = norm_output_1 @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/3072446633.py:24: RuntimeWarning: overflow encountered in matmul\n",
      "  hidden = norm_output_1 @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/3072446633.py:24: RuntimeWarning: invalid value encountered in matmul\n",
      "  hidden = norm_output_1 @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/3072446633.py:30: RuntimeWarning: divide by zero encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/3072446633.py:30: RuntimeWarning: overflow encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/3072446633.py:30: RuntimeWarning: invalid value encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/2563187069.py:63: RuntimeWarning: divide by zero encountered in matmul\n",
      "  logits = transformer_output @ self.embedding_matrix.T\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/2563187069.py:63: RuntimeWarning: overflow encountered in matmul\n",
      "  logits = transformer_output @ self.embedding_matrix.T\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/2563187069.py:63: RuntimeWarning: invalid value encountered in matmul\n",
      "  logits = transformer_output @ self.embedding_matrix.T\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1583928621.py:21: RuntimeWarning: divide by zero encountered in matmul\n",
      "  queries = x @ self.W_query    # (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1583928621.py:21: RuntimeWarning: overflow encountered in matmul\n",
      "  queries = x @ self.W_query    # (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1583928621.py:21: RuntimeWarning: invalid value encountered in matmul\n",
      "  queries = x @ self.W_query    # (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1583928621.py:22: RuntimeWarning: divide by zero encountered in matmul\n",
      "  keys = x @ self.W_key         # (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1583928621.py:22: RuntimeWarning: overflow encountered in matmul\n",
      "  keys = x @ self.W_key         # (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1583928621.py:22: RuntimeWarning: invalid value encountered in matmul\n",
      "  keys = x @ self.W_key         # (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1583928621.py:23: RuntimeWarning: divide by zero encountered in matmul\n",
      "  values = x @ self.W_value     # (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1583928621.py:23: RuntimeWarning: overflow encountered in matmul\n",
      "  values = x @ self.W_value     # (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_85086/1583928621.py:23: RuntimeWarning: invalid value encountered in matmul\n",
      "  values = x @ self.W_value     # (B, T, n_embd)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(102)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(embedding_matrix)\n",
    "# Get next character predictions for 'd'\n",
    "logits = model.forward([[stoi['a'], stoi['p']]])\n",
    "model.pred([int(stoi['r'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbedb424-33cb-4758-9b3a-b58fadcda377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_batch(data, batch_size, block_size):\n",
    "\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "\n",
    "    # Generate batchs \n",
    "    for block in [0] * batch_size:\n",
    "\n",
    "        # Get random range in datast of size=block_size\n",
    "        slice_idx = random.randrange(0, len(data) - block_size)\n",
    "        x_batch.append(data[slice_idx:slice_idx+block_size])\n",
    "        y_batch.append(data[slice_idx+1:slice_idx+block_size+1])\n",
    "\n",
    "    return np.array(x_batch), np.array(y_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b99d4ea-cd1a-4262-922b-51d46859c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradients(model, max_norm=1.0):\n",
    "    total_norm = 0\n",
    "    \n",
    "    # Calculate total gradient norm\n",
    "    total_norm += np.sum(model.embedding_matrix_grad ** 2)\n",
    "    total_norm += np.sum(model.position_matrix_grad ** 2)\n",
    "    \n",
    "    for transformer in model.transformers:\n",
    "        total_norm += np.sum(transformer.W1_grad ** 2)\n",
    "        total_norm += np.sum(transformer.W2_grad ** 2)\n",
    "        total_norm += np.sum(transformer.layer_norm1.gamma_grad ** 2)\n",
    "        total_norm += np.sum(transformer.layer_norm1.beta_grad ** 2)\n",
    "        total_norm += np.sum(transformer.layer_norm2.gamma_grad ** 2)\n",
    "        total_norm += np.sum(transformer.layer_norm2.beta_grad ** 2)\n",
    "        \n",
    "        total_norm += np.sum(transformer.multi_head_attention_block.W_output_grad ** 2)\n",
    "        for head in transformer.multi_head_attention_block.heads:\n",
    "            total_norm += np.sum(head.W_query_grad ** 2)\n",
    "            total_norm += np.sum(head.W_key_grad ** 2)\n",
    "            total_norm += np.sum(head.W_value_grad ** 2)\n",
    "    \n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    \n",
    "    # Scale gradients if norm exceeds threshold\n",
    "    if total_norm > max_norm:\n",
    "        scale = max_norm / total_norm\n",
    "        \n",
    "        model.embedding_matrix_grad *= scale\n",
    "        model.position_matrix_grad *= scale\n",
    "        \n",
    "        for transformer in model.transformers:\n",
    "            transformer.W1_grad *= scale\n",
    "            transformer.W2_grad *= scale\n",
    "            transformer.layer_norm1.gamma_grad *= scale\n",
    "            transformer.layer_norm1.beta_grad *= scale\n",
    "            transformer.layer_norm2.gamma_grad *= scale\n",
    "            transformer.layer_norm2.beta_grad *= scale\n",
    "            transformer.multi_head_attention_block.W_output_grad *= scale\n",
    "            \n",
    "            for head in transformer.multi_head_attention_block.heads:\n",
    "                head.W_query_grad *= scale\n",
    "                head.W_key_grad *= scale\n",
    "                head.W_value_grad *= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b52d3-6122-440d-bb84-45336d97c4f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib notebook\n",
    "\n",
    "# Training hyperparameters\n",
    "max_iters = 25000\n",
    "learning_rate = 1e-6\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "\n",
    "np.seterr(all='ignore')\n",
    "\n",
    "# --- Plotting Initialization ---\n",
    "plot_losses = []\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "print(\"Training model\")\n",
    "\n",
    "# Training loop\n",
    "for step in range(max_iters):\n",
    "    \n",
    "    # Get a mini-batch of data\n",
    "    x_batch, y_batch = get_batch(data, batch_size, block_size)\n",
    "    \n",
    "    # Calculate loss and probabilites\n",
    "    logits = model.forward(x_batch)\n",
    "    loss_initial, probabilities = model.calc_loss(logits, y_batch)\n",
    "\n",
    "    plot_losses.append(loss_initial)\n",
    "\n",
    "    # Backward Pass\n",
    "    one_hot_array = np.eye(vocab_size)[y_batch]\n",
    "    initial_gradient = probabilities - one_hot_array\n",
    "    \n",
    "    model.backward(initial_gradient)\n",
    "\n",
    "    # Optimizer\n",
    "    model.optimizer(learning_rate)\n",
    "\n",
    "    if step % 5 == 0:\n",
    "        print(f\"Step {step}, Loss: {loss_initial}\")\n",
    "        \n",
    "        # Graph plot\n",
    "        display.clear_output(wait=True)\n",
    "        ax.clear()\n",
    "        ax.plot(plot_losses)\n",
    "        ax.set_title(\"Training Loss Over Time\")\n",
    "        ax.set_xlabel(\"Steps (x10)\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        if loss_initial < 4:\n",
    "            ax.set_ylim(top=4) # cut off loses higher than 4\n",
    "        display.display(fig)\n",
    "\n",
    "# Final clear to show the last plot cleanly\n",
    "display.clear_output(wait=True)\n",
    "ax.clear()\n",
    "ax.plot(plot_losses)\n",
    "ax.set_title(\"Final Training Loss\")\n",
    "ax.set_xlabel(\"Steps (x100)\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "\n",
    "print(f\"Model loss: {model.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c51fdb-adad-4359-b567-8a3b7820b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56422fef-b50a-447f-90db-64d249352c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control the model's 'creativity'\n",
    "temperature = .9\n",
    "model.temperature = temperature\n",
    "\n",
    "# Let the model generate some code!\n",
    "initial_char = \"def app()\"\n",
    "\n",
    "generation_length = 500\n",
    "charIdxs = []\n",
    "\n",
    "for char in initial_char:\n",
    "    charIdxs.append(stoi[char])\n",
    "\n",
    "for i in range(generation_length):\n",
    "    charIdxs.append(model.pred(charIdxs))\n",
    "\n",
    "char_preds = [itos[charIdx] for charIdx in charIdxs]\n",
    "print(\"\".join(char_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46cddf-3b26-45fb-b67d-be92311937f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile all model weights into organized python dict\n",
    "weights_dict = {\n",
    "    \"embedding_matrix\": model.embedding_matrix,\n",
    "    \"position_matrix\": model.position_matrix,\n",
    "}\n",
    "\n",
    "for idx, transformer in enumerate(model.transformers):\n",
    "    weights_dict[f\"transform.{idx}.W1\"] = transformer.W1\n",
    "    weights_dict[f\"transform.{idx}.W2\"] = transformer.W2\n",
    "    weights_dict[f\"transform.{idx}.layer_norm1.gamma\"] = transformer.layer_norm1.gamma\n",
    "    weights_dict[f\"transform.{idx}.layer_norm1.beta\"] = transformer.layer_norm1.beta\n",
    "    weights_dict[f\"transform.{idx}.layer_norm2.gamma\"] = transformer.layer_norm2.gamma\n",
    "    weights_dict[f\"transform.{idx}.layer_norm2.beta\"] = transformer.layer_norm2.beta\n",
    "    weights_dict[f\"transform.{idx}.multi_head_attention_block.W_output\"] = transformer.multi_head_attention_block.W_output\n",
    "    \n",
    "    for index, attention_head in enumerate(transformer.multi_head_attention_block.heads):\n",
    "        weights_dict[f\"transform.{idx}.multi_head_attention_block.heads.{index}.key\"] = attention_head.W_key\n",
    "        weights_dict[f\"transform.{idx}.multi_head_attention_block.heads.{index}.query\"] = attention_head.W_query\n",
    "        weights_dict[f\"transform.{idx}.multi_head_attention_block.heads.{index}.value\"] = attention_head.W_value\n",
    "\n",
    "# Save to compressed model file \n",
    "np.savez_compressed('my_model.npz', **weights_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython",
   "language": "python",
   "name": "ipython_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
