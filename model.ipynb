{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69190936-2cb0-43d8-ade5-62beaaa0eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: source code for 'requests' python libraray\n",
    "text = open(\"data/requests.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c746ba6-353b-47cd-b79f-fa3edf0d3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sorted list of all unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# string-to-integer mapping\n",
    "stoi = { char:i for i,char in enumerate(chars) }\n",
    "\n",
    "# integer-to-string mapping\n",
    "itos = { i:char for i,char in enumerate(chars) }\n",
    "\n",
    "# lookup functions for the mappings\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "# encode the entire text file and convert to a numpy array\n",
    "data = np.array(encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f140ef1f-7dec-441a-b7fe-eb4448291514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Each character has weights of a 32 long vector, defined by n_embed (embedding dimension)\n",
    "n_embd = 32\n",
    "\n",
    "# Max input sequence length\n",
    "max_seq_len = 1000\n",
    "\n",
    "# Initialize embedding matrix\n",
    "embedding_matrix = np.random.randn(vocab_size, n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45bb0e9-1941-434c-8e8f-4681cd4ad403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_pred, y_true):\n",
    "\n",
    "    # Add a small epsilon to the prediction to avoid log(0), which is undefined.\n",
    "    epsilon = 1e-9\n",
    "    \n",
    "    # cross-entropy formula\n",
    "    loss = -np.sum(y_true * np.log(y_pred + epsilon))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feabbdb1-b5f2-4579-97f4-e80bc4f055cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_attention_block:\n",
    "    def __init__(self, W_query, W_key, W_value):\n",
    "        \n",
    "        self.W_query   = W_query \n",
    "        self.W_key = W_key \n",
    "        self.W_value = W_value\n",
    "\n",
    "        self.W_query_grad = np.zeros_like(self.W_query)\n",
    "        self.W_key_grad = np.zeros_like(self.W_key)\n",
    "        self.W_value_grad = np.zeros_like(self.W_value)\n",
    "\n",
    "        self.cache = {}\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        self.cache['x'] = x\n",
    "\n",
    "        B, T, n_embd = x.shape\n",
    "        \n",
    "        queries = x @ self.W_query    # (B, T, n_embd)\n",
    "        keys = x @ self.W_key         # (B, T, n_embd) \n",
    "        values = x @ self.W_value     # (B, T, n_embd)\n",
    "\n",
    "        self.cache['queries'] = queries  \n",
    "        self.cache['keys'] = keys\n",
    "        self.cache['values'] = values\n",
    "\n",
    "        # Make key query attention pattern\n",
    "        # Divide by sqrt of dimension for numerical stability\n",
    "        attention_scores = (queries @ keys.transpose(0, 2, 1)) / np.sqrt(keys.shape[-1])\n",
    "        self.cache['attention_scores'] = attention_scores\n",
    "\n",
    "        # Causal mask\n",
    "        mask = np.tril(np.ones((T, T))) == 0  # Upper triangle is True\n",
    "        attention_scores[:, mask] = -np.inf  # Apply mask to all batches\n",
    "\n",
    "        # softmax\n",
    "        stable_scores = attention_scores - np.max(attention_scores, axis=-1, keepdims=True)\n",
    "        attention_weights = np.exp(stable_scores) / np.sum(np.exp(stable_scores), axis=-1, keepdims=True)\n",
    "        self.cache['attn_weights'] = attention_weights\n",
    "        \n",
    "        # final output: attended inputs\n",
    "        output = attention_weights @ values  # (B, T, n_embd)\n",
    "\n",
    "        return output\n",
    "        \n",
    "    def backward(self, d_output):\n",
    "        \n",
    "        # Gradient through: output = attention_weights @ values\n",
    "        d_attention_weights = d_output @ self.cache['values'].transpose(0, 2, 1)\n",
    "        d_values = self.cache['attn_weights'].transpose(0, 2, 1) @ d_output  \n",
    "\n",
    "        # Apply jacobian to backprop through the softmax function\n",
    "        d_attention_scores = self.cache['attn_weights'] * (d_attention_weights - np.sum(d_attention_weights * self.cache['attn_weights'], axis=-1, keepdims=True))\n",
    "\n",
    "        # Scale factor\n",
    "        scale = 1.0 / np.sqrt(self.cache['keys'].shape[-1])\n",
    "        \n",
    "        # Gradient through scaling\n",
    "        d_attention_scores_scaled = d_attention_scores * scale\n",
    "        \n",
    "        # Gradient through: queries @ keys.transpose(0, 2, 1)\n",
    "        d_queries = d_attention_scores_scaled @ self.cache['keys']\n",
    "        d_keys = d_attention_scores_scaled.transpose(0, 2, 1) @ self.cache['queries']\n",
    "\n",
    "        # Gradient through: queries = x @ W_query (and same for keys, values)\n",
    "        self.W_query_grad, d_x_from_queries = self.linear_backward(d_queries, self.W_query, self.cache['x'])\n",
    "        self.W_key_grad, d_x_from_keys = self.linear_backward(d_keys, self.W_key, self.cache['x'])  \n",
    "        self.W_value_grad, d_x_from_values = self.linear_backward(d_values, self.W_value, self.cache['x'])\n",
    "        \n",
    "        # Sum gradients from all three paths\n",
    "        d_x = d_x_from_queries + d_x_from_keys + d_x_from_values\n",
    "        return d_x\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_backward(d_output, W, x_from_cache):\n",
    "        d_x = d_output @ W.T\n",
    "        x_reshaped, dy_reshaped = x_from_cache.reshape(-1, x_from_cache.shape[-1]), d_output.reshape(-1, d_output.shape[-1])\n",
    "        d_W = x_reshaped.T @ dy_reshaped\n",
    "        return d_W, d_x\n",
    "\n",
    "    def optimizer (self, learning_rate):\n",
    "        self.W_query -= (self.W_query_grad * learning_rate)\n",
    "        self.W_key -= (self.W_key_grad * learning_rate)\n",
    "        self.W_value-= (self.W_value_grad * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b1ccc6-499a-4761-ab57-e92fb293db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_head_attention:\n",
    "    def __init__ (self, n_heads, n_embd):\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = n_embd // n_heads\n",
    "\n",
    "        # Create multiple attention heads\n",
    "        self.heads = []\n",
    "        for i in range(n_heads):\n",
    "            # Each head gets its own Q, K, V projections\n",
    "            W_q = np.random.randn(n_embd, self.head_dim) * 0.02\n",
    "            W_k = np.random.randn(n_embd, self.head_dim) * 0.02\n",
    "            W_v = np.random.randn(n_embd, self.head_dim) * 0.02\n",
    "            self.heads.append(self_attention_block(W_q, W_k, W_v))\n",
    "        \n",
    "        # Output projection to combine all heads\n",
    "        self.W_output = np.random.randn(n_embd, n_embd) * 0.02\n",
    "\n",
    "        self.W_output_grad = np.zeros_like(self.W_output)\n",
    "\n",
    "        self.cache = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_backward(d_output, W, x_from_cache):\n",
    "\n",
    "        # d_W = x.T @ dy\n",
    "        # d_x = dy @ W.T\n",
    "\n",
    "        d_x = d_output @ W.T\n",
    "\n",
    "        # Flaten weight and input arrays to calculate weight gradients\n",
    "        x_reshaped, dy_reshaped = x_from_cache.reshape(-1, x_from_cache.shape[-1]), d_output.reshape(-1, d_output.shape[-1])\n",
    "        d_W = x_reshaped.T @ dy_reshaped\n",
    "\n",
    "        return d_W, d_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run each head\n",
    "        head_outputs = []\n",
    "        for head in self.heads:\n",
    "            head_outputs.append(head.forward(x))\n",
    "        \n",
    "        # Concatenate along embedding dimension\n",
    "        concat_output = np.concatenate(head_outputs, axis=-1)  # (B, T, n_embd)\n",
    "        self.cache['concat_output'] = concat_output\n",
    "        \n",
    "        # Final projection\n",
    "        output = concat_output @ self.W_output\n",
    "        return output\n",
    "\n",
    "    def backward(self, d_output):\n",
    "\n",
    "        self.W_output_grad, d_concat = self.linear_backward(d_output, self.W_output, self.cache['concat_output'])\n",
    "\n",
    "        head_gradients = np.split(d_concat, self.n_heads, axis=-1)\n",
    "\n",
    "        # Return sum of head's gradients\n",
    "        d_x_sum = None\n",
    "        for i, head_grad in enumerate(head_gradients):\n",
    "            d_x = self.heads[i].backward(head_grad)\n",
    "            if d_x_sum is None:\n",
    "                d_x_sum = d_x\n",
    "            else:\n",
    "                d_x_sum += d_x \n",
    "        \n",
    "        return d_x_sum\n",
    "\n",
    "    def optimizer(self, learning_rate):\n",
    "        self.W_output -= (self.W_output_grad * learning_rate)\n",
    "        for head in self.heads:\n",
    "            head.optimizer(learning_rate)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e42dcd-5ea2-4a38-900f-6dbd42064fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm:\n",
    "    def __init__ (self, n_embd):\n",
    "\n",
    "        self.n_embd = n_embd\n",
    "        self.gamma = np.ones((n_embd,))\n",
    "        self.beta = np.zeros((n_embd,))\n",
    "\n",
    "        self.gamma_grad = np.zeros_like(self.gamma)\n",
    "        self.beta_grad = np.zeros_like(self.beta)\n",
    "\n",
    "        self.cache = {}\n",
    "        \n",
    "    def forward (self, x):\n",
    "\n",
    "        # x: (B, T, n_embd)\n",
    "        mean = x.mean(axis=-1, keepdims=True)\n",
    "        variance = x.var(axis=-1, keepdims=True)\n",
    "        epsilon = 1e-5 # A standard small value for epsilon\n",
    "\n",
    "        # Input vector scaled to have a mean of 0 and variance of 1\n",
    "        x_normalized = (x - mean) / np.sqrt(variance + epsilon)\n",
    "        \n",
    "        # Cache values needed for the backward pass\n",
    "        self.cache['x_normalized'] = x_normalized\n",
    "        self.cache['gamma'] = self.gamma\n",
    "        self.cache['std_dev'] = np.sqrt(variance + epsilon)\n",
    "\n",
    "        return x_normalized * self.gamma + self.beta\n",
    "\n",
    "    \n",
    "    def backward (self, d_output):\n",
    "        \"\"\"\n",
    "        Calculates the gradients for gamma, beta, and the input x.\n",
    "        \"\"\"\n",
    "        # Calculate gradients for gamma and beta\n",
    "        # These are summed over the batch and time dimensions to match the parameter shapes\n",
    "        self.beta_grad = np.sum(d_output, axis=(0,1))\n",
    "        self.gamma_grad = np.sum(d_output * self.cache['x_normalized'], axis=(0,1))\n",
    "\n",
    "        # Calculate the gradient for the input x (the error signal to pass back)\n",
    "        N = self.n_embd\n",
    "        std_dev = self.cache['std_dev']\n",
    "        x_norm = self.cache['x_normalized']\n",
    "        gamma = self.cache['gamma']\n",
    "\n",
    "        # Backprop through the scale and shift (y = gamma * x_norm + beta)\n",
    "        d_x_norm = d_output * gamma\n",
    "        \n",
    "        # Backprop through the normalization\n",
    "        sum1 = np.sum(d_x_norm, axis=-1, keepdims=True)\n",
    "        sum2 = np.sum(d_x_norm * x_norm, axis=-1, keepdims=True)\n",
    "        \n",
    "        d_x = (1 / (N * std_dev)) * (N * d_x_norm - sum1 - x_norm * sum2)\n",
    "        \n",
    "        return d_x\n",
    "        \n",
    "    def optimizer (self, learning_rate):\n",
    "        \n",
    "        self.gamma -= (self.gamma_grad * learning_rate)\n",
    "        self.beta -= (self.beta_grad * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc41611e-38e2-458b-b669-eb39c0955c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__ (self, W1, W2, n_attn_heads, n_embd):\n",
    "        self.W1 = W1\n",
    "        self.W2 = W2\n",
    "        self.multi_head_attention_block = multi_head_attention(n_attn_heads, n_embd)\n",
    "\n",
    "        self.W1_grad = np.zeros_like(self.W1)\n",
    "        self.W2_grad = np.zeros_like(self.W2)\n",
    "\n",
    "        self.layer_norm1 = LayerNorm(n_embd)\n",
    "        self.layer_norm2 = LayerNorm(n_embd)\n",
    "\n",
    "        self.cache = {}\n",
    "\n",
    "    def forward (self, x): \n",
    "\n",
    "        attn_output = self.multi_head_attention_block.forward(x)\n",
    "        self.cache['attn_output'] = attn_output\n",
    "\n",
    "        add_output_1 = x + attn_output  # Residual connection step\n",
    "        norm_output_1 = self.layer_norm1.forward(add_output_1)  # Layer norm step\n",
    "        self.cache['norm_output_1'] = norm_output_1\n",
    "                \n",
    "        hidden = norm_output_1 @ self.W1\n",
    "        self.cache['hidden'] = hidden\n",
    "        \n",
    "        hidden_activated = np.maximum(0, hidden)\n",
    "        self.cache['hidden_activated'] = hidden_activated \n",
    "        \n",
    "        processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
    "        self.cache['processed_vectors'] = processed_vectors\n",
    "\n",
    "        add_output_2 = norm_output_1 + processed_vectors   # Residual connection step\n",
    "        norm_output_2 = self.layer_norm2.forward(add_output_2) # Layer norm step\n",
    "        self.cache['norm_output_2'] = norm_output_2\n",
    "\n",
    "        return norm_output_2\n",
    "\n",
    "    def backward (self, d_output):\n",
    "\n",
    "        # Error gradient from last residiual connection step, calculated on LayerNorm.backwards()\n",
    "        d_add2 = self.layer_norm2.backward(d_output)\n",
    "\n",
    "        # Fork error signal\n",
    "        d_processed_vectors = d_add2\n",
    "        d_norm_output_1_from_residual = d_add2\n",
    "\n",
    "        # Put d_processed_vectors through FFN backprop\n",
    "        # Activated hidden layer\n",
    "        grad_W2, d_hidden_activated = self.linear_backward(d_processed_vectors, self.W2, self.cache['hidden_activated'])\n",
    "        self.W2_grad = grad_W2\n",
    "\n",
    "        # Relu backprop\n",
    "        d_hidden = d_hidden_activated * (self.cache['hidden'] > 0)\n",
    "\n",
    "        # Hidden layer\n",
    "        grad_W1, d_norm_output_1_from_ffn = self.linear_backward(d_hidden, self.W1, self.cache['norm_output_1'])\n",
    "        self.W1_grad = grad_W1\n",
    "\n",
    "        # Recombine error gradients \n",
    "        d_norm_output_1_total = d_norm_output_1_from_ffn + d_norm_output_1_from_residual\n",
    "\n",
    "        # Error gradient from first residiual connection step, calculated on LayerNorm.backwards()\n",
    "        d_add1 = self.layer_norm1.backward(d_norm_output_1_total)\n",
    "\n",
    "        d_attn_output = d_add1\n",
    "        d_x_from_residual = d_add1\n",
    "\n",
    "        # Attention block    \n",
    "        d_x_from_attention = self.multi_head_attention_block.backward(d_attn_output)\n",
    "\n",
    "        d_attn_input = d_x_from_residual + d_x_from_attention\n",
    "\n",
    "        return d_attn_input\n",
    "\n",
    "    def optimizer(self, learning_rate): \n",
    "\n",
    "        self.multi_head_attention_block.optimizer(learning_rate)\n",
    "\n",
    "        self.layer_norm1.optimizer(learning_rate)\n",
    "        self.layer_norm2.optimizer(learning_rate)\n",
    "        \n",
    "        self.W1 -= (self.W1_grad * learning_rate)\n",
    "        self.W2 -= (self.W2_grad * learning_rate)\n",
    "        \n",
    "    @staticmethod\n",
    "    def linear_backward(d_output, W, x_from_cache):\n",
    "\n",
    "        # d_W = x.T @ dy\n",
    "        # d_x = dy @ W.T\n",
    "\n",
    "        d_x = d_output @ W.T\n",
    "\n",
    "        # Flaten weight and input arrays to calculate weight gradients\n",
    "        x_reshaped, dy_reshaped = x_from_cache.reshape(-1, x_from_cache.shape[-1]), d_output.reshape(-1, d_output.shape[-1])\n",
    "        d_W = x_reshaped.T @ dy_reshaped\n",
    "\n",
    "        return d_W, d_x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce4f567-ea96-4ec9-9349-6fdcac190fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,embedding_matrix, temperature=1.0, max_sequence_length=1000, n_embd=32, n_transformers=6, ffwd_expansion_factor=4):\n",
    "\n",
    "        # Initialize weight matrices\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.unembedding_matrix = embedding_matrix.transpose()\n",
    "        self.position_matrix = np.random.randn(max_sequence_length, n_embd)\n",
    "\n",
    "        # Hidden layer initialization functions\n",
    "        \n",
    "        # Transformers \n",
    "        self.transformers = []\n",
    "        \n",
    "        for i in range(n_transformers):\n",
    "            \n",
    "            # Hidden layer initialization \n",
    "            W1 = np.random.randn(n_embd, n_embd * ffwd_expansion_factor) * np.sqrt(2.0 / n_embd)\n",
    "            W2 = np.random.randn(n_embd * ffwd_expansion_factor, n_embd) * np.sqrt(2.0 / (n_embd * ffwd_expansion_factor))\n",
    "\n",
    "            # Append transformer\n",
    "            self.transformers.append(Transformer(W1, W2, n_attn_heads=16, n_embd=n_embd))\n",
    "\n",
    "        self.cache = {} # A dictionary to store forward pass values\n",
    "\n",
    "        self.n_transformers = n_transformers\n",
    "\n",
    "        # Temperature hyperparameter\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Gradient buckets\n",
    "        self.embedding_matrix_grad = np.zeros_like(self.embedding_matrix)\n",
    "        self.position_matrix_grad = np.zeros_like(self.position_matrix)\n",
    "\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        \n",
    "        x_batch = np.array(x_batch)\n",
    "        if x_batch.ndim == 1:\n",
    "            x_batch = x_batch[None, :]  # Add batch dimension: (T,) -> (1, T)\n",
    "        \n",
    "        self.cache['x_batch'] = x_batch\n",
    "\n",
    "        # Output shape: (B, T, n_embd)\n",
    "        embd = self.embedding_matrix[x_batch]\n",
    "        self.cache['embd'] = embd\n",
    "\n",
    "        # Positional embeddings\n",
    "        B, T = x_batch.shape\n",
    "        pos = self.position_matrix[:T]  # Slice for sequence length\n",
    "        self.cache['pos'] = pos\n",
    "        \n",
    "        # Add position to token embeddings\n",
    "        attn_input = embd + pos\n",
    "        self.cache['attn_input'] = attn_input\n",
    "        \n",
    "        # Put data through transformers\n",
    "        transformer_output = attn_input\n",
    "        \n",
    "        for transformer in self.transformers:\n",
    "            transformer_output = transformer.forward(transformer_output)\n",
    "            \n",
    "        self.cache['transformer_output'] = transformer_output\n",
    "        \n",
    "        logits = transformer_output @ self.unembedding_matrix\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def pred (self, x):\n",
    "\n",
    "        logits = self.forward(x)[0, -1]  # Get batch 0, last position\n",
    "        \n",
    "        scaled_logits = logits / self.temperature\n",
    "        \n",
    "        ## Apply softmax function to logits\n",
    "        stable_logits = scaled_logits - np.max(scaled_logits) # This ensures the largest logit is 0\n",
    "        preds = np.exp(stable_logits) / np.sum(np.exp(stable_logits))       \n",
    "        \n",
    "        char_pred = np.random.choice(range(0, len(chars)), p=preds)\n",
    "        \n",
    "        return char_pred\n",
    "\n",
    "    def calc_loss (self, logits, y_batch):\n",
    "\n",
    "        # Get the dimensions for indexing\n",
    "        B, T, C = logits.shape\n",
    "\n",
    "        # Stable softmax\n",
    "        max_logits = np.max(logits, axis=-1, keepdims=True)\n",
    "        stable_logits = logits - max_logits\n",
    "        exp_logits = np.exp(stable_logits)\n",
    "        probabilities = exp_logits / np.sum(exp_logits, axis=-1, keepdims=True)\n",
    "    \n",
    "        # Get the probabilities for the correct target characters using efficient indexing\n",
    "        correct_char_probs = probabilities[np.arange(B)[:, None], np.arange(T), y_batch]\n",
    "\n",
    "        # Calculate negative log likelihood\n",
    "        loss_array = -np.log(correct_char_probs + 1e-9)\n",
    "    \n",
    "        # Average the loss over the whole batch to get a single number\n",
    "        mean_loss = np.mean(loss_array)\n",
    "\n",
    "        self.loss = mean_loss\n",
    "        \n",
    "        # Return probabilities because they are the starting point for backpropagation\n",
    "        return mean_loss, probabilities\n",
    "\n",
    "    \n",
    "    # Calculates the gradients for a specific layer and it's resulting vector\n",
    "    @staticmethod\n",
    "    def linear_backward(d_output, W, x_from_cache):\n",
    "\n",
    "        # d_W = x.T @ dy\n",
    "        # d_x = dy @ W.T\n",
    "\n",
    "        d_x = d_output @ W.T\n",
    "\n",
    "        # Flaten weight and input arrays to calculate weight gradients\n",
    "        x_reshaped, dy_reshaped = x_from_cache.reshape(-1, x_from_cache.shape[-1]), d_output.reshape(-1, d_output.shape[-1])\n",
    "        d_W = x_reshaped.T @ dy_reshaped\n",
    "\n",
    "        return d_W, d_x\n",
    "\n",
    "\n",
    "    def backward (self, d_logits):\n",
    "\n",
    "        # unembedding layer\n",
    "        grad_unembed, d_transformer_output = self.linear_backward(\n",
    "            d_logits, \n",
    "            self.unembedding_matrix, \n",
    "            self.cache['transformer_output']\n",
    "        )\n",
    "        self.embedding_matrix_grad = grad_unembed.transpose()\n",
    "    \n",
    "        # Loop in reverse order through transformers\n",
    "        current_grad = d_transformer_output\n",
    "        \n",
    "        for transformer in reversed(self.transformers):\n",
    "            current_grad = transformer.backward(current_grad)\n",
    "\n",
    "        d_attn_input = current_grad\n",
    "\n",
    "\n",
    "         # Split gradient between embeddings and positions (attn_input = embd + pos)\n",
    "        d_embed = d_attn_input  \n",
    "        d_pos = d_attn_input  \n",
    "        \n",
    "        # Update position matrix gradients\n",
    "        B, T = self.cache['x_batch'].shape\n",
    "        self.position_matrix_grad = np.zeros_like(self.position_matrix)\n",
    "        self.position_matrix_grad[:T] += np.sum(d_pos, axis=0)  # Sum over batch dimension\n",
    "    \n",
    "        # Perform reverse lookup on embedding array\n",
    "        np.add.at(self.embedding_matrix_grad, self.cache['x_batch'], d_embed)\n",
    "\n",
    "    def optimizer (self, learning_rate): \n",
    "\n",
    "        self.embedding_matrix -= (self.embedding_matrix_grad * learning_rate)\n",
    "        self.position_matrix -= (self.position_matrix_grad * learning_rate)\n",
    "        \n",
    "        for transformer in self.transformers:\n",
    "            transformer.optimizer(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6aef4e4-a5fd-4b7f-992a-eabd50c53183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/3072446633.py:24: RuntimeWarning: divide by zero encountered in matmul\n",
      "  hidden = norm_output_1 @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/3072446633.py:24: RuntimeWarning: overflow encountered in matmul\n",
      "  hidden = norm_output_1 @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/3072446633.py:24: RuntimeWarning: invalid value encountered in matmul\n",
      "  hidden = norm_output_1 @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/3072446633.py:30: RuntimeWarning: divide by zero encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/3072446633.py:30: RuntimeWarning: overflow encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/3072446633.py:30: RuntimeWarning: invalid value encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/812391413.py:64: RuntimeWarning: divide by zero encountered in matmul\n",
      "  logits = transformer_output @ self.unembedding_matrix\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/812391413.py:64: RuntimeWarning: overflow encountered in matmul\n",
      "  logits = transformer_output @ self.unembedding_matrix\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/812391413.py:64: RuntimeWarning: invalid value encountered in matmul\n",
      "  logits = transformer_output @ self.unembedding_matrix\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/1034086775.py:47: RuntimeWarning: divide by zero encountered in matmul\n",
      "  output = concat_output @ self.W_output\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/1034086775.py:47: RuntimeWarning: overflow encountered in matmul\n",
      "  output = concat_output @ self.W_output\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_35957/1034086775.py:47: RuntimeWarning: invalid value encountered in matmul\n",
      "  output = concat_output @ self.W_output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(embedding_matrix)\n",
    "# Get next character predictions for 'd'\n",
    "logits = model.forward([[stoi['a'], stoi['p']]])\n",
    "model.pred([int(stoi['r'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbedb424-33cb-4758-9b3a-b58fadcda377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_batch(data, batch_size, block_size):\n",
    "\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "\n",
    "    # Generate batchs \n",
    "    for block in [0] * batch_size:\n",
    "\n",
    "        # Get random range in datast of size=block_size\n",
    "        slice_idx = random.randrange(0, len(data) - block_size)\n",
    "        x_batch.append(data[slice_idx:slice_idx+block_size])\n",
    "        y_batch.append(data[slice_idx+1:slice_idx+block_size+1])\n",
    "\n",
    "    return np.array(x_batch), np.array(y_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b52d3-6122-440d-bb84-45336d97c4f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib notebook\n",
    "\n",
    "# Training hyperparameters\n",
    "max_iters = 20000\n",
    "learning_rate = 3e-5\n",
    "batch_size = 32\n",
    "block_size = 256\n",
    "\n",
    "np.seterr(all='ignore')\n",
    "\n",
    "# --- Plotting Initialization ---\n",
    "plot_losses = []\n",
    "fig, ax = plt.subplots()\n",
    "# ---\n",
    "\n",
    "# Training loop\n",
    "for step in range(max_iters):\n",
    "    \n",
    "    # Get a mini-batch of data\n",
    "    # Note: Corrected the order of batch_size and block_size from user's original training loop code\n",
    "    x_batch, y_batch = get_batch(data, block_size, batch_size)\n",
    "\n",
    "    \n",
    "    # Calculate loss and probabilites\n",
    "    logits = model.forward(x_batch)\n",
    "    loss_initial, probabilities = model.calc_loss(logits, y_batch)\n",
    "\n",
    "    plot_losses.append(loss_initial)\n",
    "\n",
    "    # Backward Pass\n",
    "    one_hot_array = np.eye(vocab_size)[y_batch]\n",
    "    initial_gradient = probabilities - one_hot_array\n",
    "    \n",
    "    model.backward(initial_gradient)\n",
    "        \n",
    "    # Optimizer\n",
    "    model.optimizer(learning_rate)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}, Loss: {loss_initial}\")\n",
    "        \n",
    "        # --- Live Plotting Logic ---\n",
    "        display.clear_output(wait=True)\n",
    "        ax.clear()\n",
    "        ax.plot(plot_losses)\n",
    "        ax.set_title(\"Training Loss Over Time\")\n",
    "        ax.set_xlabel(\"Steps (x100)\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_ylim(top=3) # cut off loses higher than 3\n",
    "        display.display(fig)\n",
    "        # ---\n",
    "\n",
    "# Final clear to show the last plot cleanly\n",
    "display.clear_output(wait=True)\n",
    "ax.clear()\n",
    "ax.plot(plot_losses)\n",
    "ax.set_title(\"Final Training Loss\")\n",
    "ax.set_xlabel(\"Steps (x100)\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "\n",
    "print(f\"Model loss: {model.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56422fef-b50a-447f-90db-64d249352c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control the model's 'creativity'\n",
    "temperature = .5\n",
    "model.temperature = temperature\n",
    "\n",
    "# Let the model generate some code!\n",
    "initial_char = \"\\n\"\n",
    "\n",
    "generation_length = 500\n",
    "charIdxs = [int(stoi[initial_char])]\n",
    "\n",
    "for i in range(generation_length):\n",
    "    charIdxs.append(model.pred(charIdxs))\n",
    "\n",
    "char_preds = [itos[charIdx] for charIdx in charIdxs]\n",
    "print(\"\".join(char_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48501b98-b1d0-4376-99e6-c13cabd9b450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython",
   "language": "python",
   "name": "ipython_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
