{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69190936-2cb0-43d8-ade5-62beaaa0eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: source code for 'requests' python libraray\n",
    "text = open(\"data/requests.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c746ba6-353b-47cd-b79f-fa3edf0d3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sorted list of all unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# string-to-integer mapping\n",
    "stoi = { char:i for i,char in enumerate(chars) }\n",
    "\n",
    "# integer-to-string mapping\n",
    "itos = { i:char for i,char in enumerate(chars) }\n",
    "\n",
    "# lookup functions for the mappings\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "# encode the entire text file and convert to a numpy array\n",
    "data = np.array(encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f140ef1f-7dec-441a-b7fe-eb4448291514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Each character has weights of a 32 long vector, defined by n_embed (embedding dimension)\n",
    "n_embd = 32\n",
    "\n",
    "# Initialize embedding & unembedding matrix\n",
    "embedding_matrix = np.random.randn(vocab_size, n_embd)\n",
    "unembedding_matrix = np.random.randn(n_embd, vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b31441d-4b8c-4ce4-ac79-673775407b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard expansion factor of four\n",
    "ffwd_expansion_factor = 4\n",
    "\n",
    "# Initialize hidden layer and output layer\n",
    "# Use Kaiming init to intelligently scale the layer's random weights\n",
    "W1 = np.random.randn(n_embd, n_embd * ffwd_expansion_factor) * np.sqrt(2.0 / n_embd)\n",
    "W2 = np.random.randn(n_embd * ffwd_expansion_factor, n_embd) * np.sqrt(2.0 / n_embd)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a45bb0e9-1941-434c-8e8f-4681cd4ad403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_pred, y_true):\n",
    "\n",
    "    # Add a small epsilon to the prediction to avoid log(0), which is undefined.\n",
    "    epsilon = 1e-9\n",
    "    \n",
    "    # cross-entropy formula\n",
    "    loss = -np.sum(y_true * np.log(y_pred + epsilon))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6ce4f567-ea96-4ec9-9349-6fdcac190fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,embedding_matrix, unembedding_matrix, W1, W2):\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.unembedding_matrix = unembedding_matrix\n",
    "        self.W1 = W1\n",
    "        self.W2 = W2\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        \n",
    "        # Output shape: (B, T, n_embd)\n",
    "        embd = self.embedding_matrix[x_batch]\n",
    "\n",
    "        hidden = embd @ self.W1\n",
    "        hidden_activated = np.maximum(0, hidden)\n",
    "        processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
    "\n",
    "        # Final projection to logits\n",
    "        logits = processed_vectors @ self.unembedding_matrix\n",
    "        \n",
    "        return logits\n",
    "\n",
    "    def pred (self, x):\n",
    "\n",
    "        logits = self.forward(x)\n",
    "\n",
    "        ## Apply softmax function to logits\n",
    "        stable_logits = logits - np.max(logits) # This ensures the largest logit is 0\n",
    "        raw_preds = np.exp(stable_logits) / np.sum(np.exp(stable_logits))        \n",
    "        preds = {}\n",
    "\n",
    "        for idx, raw_pred in enumerate(raw_preds):\n",
    "\n",
    "            preds[itos[idx]] = raw_pred\n",
    "        \n",
    "        return preds\n",
    "\n",
    "    def loss (self, logits, y_batch):\n",
    "\n",
    "        # Get the dimensions for indexing\n",
    "        B, T, C = logits.shape\n",
    "\n",
    "        # Stable softmax\n",
    "        max_logits = np.max(logits, axis=-1, keepdims=True)\n",
    "        stable_logits = logits - max_logits\n",
    "        exp_logits = np.exp(stable_logits)\n",
    "        probabilities = exp_logits / np.sum(exp_logits, axis=-1, keepdims=True)\n",
    "    \n",
    "        # Get the probabilities for the correct target characters using efficient indexing\n",
    "        correct_char_probs = probabilities[np.arange(B)[:, None], np.arange(T), y_batch]\n",
    "\n",
    "        # Calculate negative log likelihood\n",
    "        loss_array = -np.log(correct_char_probs + 1e-9)\n",
    "    \n",
    "        # Average the loss over the whole batch to get a single number\n",
    "        mean_loss = np.mean(loss_array)\n",
    "    \n",
    "        # Return probabilities because they are the starting point for backpropagation\n",
    "        return mean_loss, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d6aef4e4-a5fd-4b7f-992a-eabd50c53183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:13: RuntimeWarning: divide by zero encountered in matmul\n",
      "  hidden = embd @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:13: RuntimeWarning: overflow encountered in matmul\n",
      "  hidden = embd @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:13: RuntimeWarning: invalid value encountered in matmul\n",
      "  hidden = embd @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:15: RuntimeWarning: divide by zero encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:15: RuntimeWarning: overflow encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:15: RuntimeWarning: invalid value encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:18: RuntimeWarning: divide by zero encountered in matmul\n",
      "  logits = processed_vectors @ self.unembedding_matrix\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:18: RuntimeWarning: overflow encountered in matmul\n",
      "  logits = processed_vectors @ self.unembedding_matrix\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:18: RuntimeWarning: invalid value encountered in matmul\n",
      "  logits = processed_vectors @ self.unembedding_matrix\n"
     ]
    }
   ],
   "source": [
    "model = Model(embedding_matrix, unembedding_matrix, W1, W2)\n",
    "# Get next character predictions for 'd'\n",
    "logits = model.forward([stoi['d'],stoi['d']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dbedb424-33cb-4758-9b3a-b58fadcda377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_batch(data, batch_size, block_size):\n",
    "\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "\n",
    "    # Generate batchs \n",
    "    for block in [0] * batch_size:\n",
    "\n",
    "        # Get random range in datast of size=block_size\n",
    "        slice_idx = random.randrange(0, len(data) - block_size)\n",
    "        x_batch.append(data[slice_idx:slice_idx+block_size])\n",
    "        y_batch.append(data[slice_idx+1:slice_idx+block_size+1])\n",
    "\n",
    "    return np.array(x_batch), np.array(y_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3f7b52d3-6122-440d-bb84-45336d97c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 16.23490803   5.42676734  28.87936671 ...  -2.94016662  30.17489851\n",
      "   -19.97881587]\n",
      "  [ 14.33743883  -2.44574008  17.00839391 ...  -0.85616978  26.47614349\n",
      "   -20.21357627]\n",
      "  [ 45.80885095  17.923195     7.61935221 ...  24.74539571  12.13482784\n",
      "     2.22955933]\n",
      "  ...\n",
      "  [  4.85144256 -14.60702026  -8.63936801 ...   6.11538346   2.898202\n",
      "    21.59168967]\n",
      "  [  4.85144256 -14.60702026  -8.63936801 ...   6.11538346   2.898202\n",
      "    21.59168967]\n",
      "  [  4.85144256 -14.60702026  -8.63936801 ...   6.11538346   2.898202\n",
      "    21.59168967]]\n",
      "\n",
      " [[  4.85144256 -14.60702026  -8.63936801 ...   6.11538346   2.898202\n",
      "    21.59168967]\n",
      "  [  4.85144256 -14.60702026  -8.63936801 ...   6.11538346   2.898202\n",
      "    21.59168967]\n",
      "  [  4.85144256 -14.60702026  -8.63936801 ...   6.11538346   2.898202\n",
      "    21.59168967]\n",
      "  ...\n",
      "  [  8.04645693  12.72710851   1.98806376 ... -10.02812498   7.78929489\n",
      "    -3.81596985]\n",
      "  [  1.39216115  -1.3638196   22.15307323 ...   6.26748186   6.99444994\n",
      "   -10.81259746]\n",
      "  [  1.39216115  -1.3638196   22.15307323 ...   6.26748186   6.99444994\n",
      "   -10.81259746]]\n",
      "\n",
      " [[  5.7106316   -6.51033062  57.41737068 ...  11.98849733  26.97936998\n",
      "   -23.37487158]\n",
      "  [  1.12194708  31.91522552  36.10129667 ...  12.9407463   11.89658173\n",
      "   -23.34642291]\n",
      "  [ 46.59492779   7.63855072   9.78176569 ...   6.07891832  18.45672058\n",
      "     6.32082036]\n",
      "  ...\n",
      "  [  1.12194708  31.91522552  36.10129667 ...  12.9407463   11.89658173\n",
      "   -23.34642291]\n",
      "  [ 46.59492779   7.63855072   9.78176569 ...   6.07891832  18.45672058\n",
      "     6.32082036]\n",
      "  [ -1.26700839  10.13338547  10.03605557 ...   9.28448622   8.79854504\n",
      "     4.73033466]]\n",
      "\n",
      " [[  4.85144256 -14.60702026  -8.63936801 ...   6.11538346   2.898202\n",
      "    21.59168967]\n",
      "  [  4.85144256 -14.60702026  -8.63936801 ...   6.11538346   2.898202\n",
      "    21.59168967]\n",
      "  [  4.85144256 -14.60702026  -8.63936801 ...   6.11538346   2.898202\n",
      "    21.59168967]\n",
      "  ...\n",
      "  [  3.31758976  -8.38411798  58.1232044  ...  12.13462724   7.97737994\n",
      "    -7.61213714]\n",
      "  [  3.31758976  -8.38411798  58.1232044  ...  12.13462724   7.97737994\n",
      "    -7.61213714]\n",
      "  [ 45.80885095  17.923195     7.61935221 ...  24.74539571  12.13482784\n",
      "     2.22955933]]]\n",
      "Loss: 19.383698434097465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:13: RuntimeWarning: divide by zero encountered in matmul\n",
      "  hidden = embd @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:13: RuntimeWarning: overflow encountered in matmul\n",
      "  hidden = embd @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:13: RuntimeWarning: invalid value encountered in matmul\n",
      "  hidden = embd @ self.W1\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:15: RuntimeWarning: divide by zero encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:15: RuntimeWarning: overflow encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:15: RuntimeWarning: invalid value encountered in matmul\n",
      "  processed_vectors = hidden_activated @ self.W2 # Shape: (B, T, n_embd)\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:18: RuntimeWarning: divide by zero encountered in matmul\n",
      "  logits = processed_vectors @ self.unembedding_matrix\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:18: RuntimeWarning: overflow encountered in matmul\n",
      "  logits = processed_vectors @ self.unembedding_matrix\n",
      "/var/folders/8k/dg_kyxnn5wn4nbhpwfq40c2r0000gn/T/ipykernel_19714/2117368429.py:18: RuntimeWarning: invalid value encountered in matmul\n",
      "  logits = processed_vectors @ self.unembedding_matrix\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predicted_probabilities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_initial\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m one_hot_array = np.eye(vocab_size)[y_batch]\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m initial_gradient = \u001b[43mpredicted_probabilities\u001b[49m - one_hot_array\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Backward Pass\u001b[39;00m\n\u001b[32m     29\u001b[39m model.backward()\n",
      "\u001b[31mNameError\u001b[39m: name 'predicted_probabilities' is not defined"
     ]
    }
   ],
   "source": [
    "# Training hyperparameters\n",
    "max_iters = 5000\n",
    "learning_rate = 1e-3 # A common starting point for learning rate\n",
    "eval_interval = 500  # How often we'll print the loss\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "# Training loop\n",
    "for step in range(max_iters):\n",
    "    \n",
    "    # Get a mini-batch of data\n",
    "    x_batch, y_batch = get_batch(data, batch_size, block_size)\n",
    "\n",
    "    \n",
    "    # Calculate loss and probabilites\n",
    "    logits = model.forward(x_batch)\n",
    "    loss_initial, probabilities = model.loss(logits, y_batch)\n",
    "\n",
    "    print(f\"Loss: {loss_initial}\")\n",
    "\n",
    "    one_hot_array = np.eye(vocab_size)[y_batch]\n",
    "\n",
    "    print(one_hot_array\n",
    "    initial_gradient = predicted_probabilities - one_hot_array\n",
    "\n",
    "    \n",
    "          \n",
    "    # Backward Pass\n",
    "    model.backward()\n",
    "    \n",
    "    # Optimizer step (Updated weights with gradients)\n",
    "    for param in model.parameters():\n",
    "        param -= learning_rate * param.grad \n",
    "        \n",
    "    # Print out the loss periodically\n",
    "    if step % eval_interval == 0:\n",
    "        print(f\"Step {step}: Training Loss = {loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48501b98-b1d0-4376-99e6-c13cabd9b450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython",
   "language": "python",
   "name": "ipython_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
